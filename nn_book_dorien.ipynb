{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a969fe-fa76-4814-baf7-959aaa9eb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf3927-4efc-43ce-b81a-f72ae7af7e16",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64dbe5a6-2c43-4cf1-83f2-634239ff81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #initialization function to create network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): #these are the things we need to initialize a NN\n",
    "        \"\"\"\n",
    "        Applies the parameters to the neural network object, network has one hidden layer.\n",
    "        \n",
    "        :param inputnodes: number of nodes in input layer\n",
    "        :param hiddennodes: number of nodes in hidden layer\n",
    "        :param outputnodes: number of nodes in output layer\n",
    "        :param learningrate: learning rate of gradient descent        \n",
    "        :type inputnodes: int\n",
    "        :type hiddennodes: int\n",
    "        :type outputnodes: int\n",
    "        :type learningrate: int\n",
    "        \n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        #assigning these variables to the object: \n",
    "        self.inodes = inputnodes \n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        #matrix of random weigths (w) that link input layer (i) to hidden layer (h)\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        \n",
    "        #matrix of random weights (w) that link hidden layer (h) to output later (o)\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # defining the activation function, in this case the sigmoid (called expit here)\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)  \n",
    "        \n",
    "        #defining the reverse activation function for backwards query, called logit\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # training phase\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \"\"\"\n",
    "        Coverts input to output through the network and backpropagates the error to update weights, thereby training the NN\n",
    "        \n",
    "        :param inputs_list: training features\n",
    "        :param targets_list: training labels or target output\n",
    "        :type inputs_list: list\n",
    "        :type targets_list: list\n",
    "        \n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        \n",
    "        ###part 1: going from input to output:\n",
    "        \n",
    "        # convert inputs list to 2d array (matrix)\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer by applying weights to inputlayer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer by applying activation function\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer by applying weights to output from hidden layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer by applying activation function\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        ###part 2: backpropagating error\n",
    "        \n",
    "        # output layer error is the target output minus the actual output\n",
    "        #note: output_errors is still a matrix, and thus contains all the errors for every datapoint separately. targets and final_outputs are also arrays\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        # so, (transposed) hidden-output weights matrix is multiplied with the output error matrix\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        pass\n",
    "    \n",
    "    # query fase\n",
    "    def query(self, inputs_list):\n",
    "        \"\"\"\n",
    "        Gives predictions based on input. \n",
    "        \n",
    "        inputs_list: list \n",
    "        returns: array with output\n",
    "        \"\"\"\n",
    "        # convert inputs_list to matrix, and transposes so input is a column not a row\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer: use matrix multiplication of weights and input\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # apply activation (sigmoid) to calculate what comes out of hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer: matrix multiplication of weights and input (in this case output from previous layer)\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # apply activation (sigmoid) to calculate what comes out of output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        \n",
    "        return final_outputs \n",
    "    \n",
    "        \n",
    "    # backquery the neural network\n",
    "    # target are the values at the right of the network, albeit used as input\n",
    "    # hidden_output is the signal to the right of the middle nodes\n",
    "\n",
    "    def backquery(self, targets_list):\n",
    "        \"\"\"\n",
    "        Feed the network target output and get an image back, by going backwards throught the network. \n",
    "        \n",
    "        :param targets_list: list of target outputs\n",
    "        :type targets_list: list\n",
    "        \n",
    "        returns: input (image)\n",
    "        \"\"\"\n",
    "        # transpose the targets list to a vertical array\n",
    "        # same as in query()\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # we are going backwards, so first the reverse activation function is applied\n",
    "        # calculate the signal into the final output layer using the inverse act funct (see __init__())\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "        \n",
    "        # calculate the signal out of the hidden layer, weights matrix is transposed\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer, weights matrix is transposed\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99791d8-c8bf-4a60-a966-16020ee117f1",
   "metadata": {},
   "source": [
    "## Making an NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0155e6b4-8110-4e9e-93e8-919aeba71b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing\n",
    "# making a nn with specific number of nodes\n",
    "\n",
    "input_n = 784 #28*28 pixels so 784 inputs\n",
    "hidden_n = 350\n",
    "output_n = 10 #we have 10 target outputs so 10 output nodes\n",
    "l_r = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0fda626-8881-4fd0-b7fd-8483ce7cafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = neuralNetwork(input_n, hidden_n, output_n, l_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7bd67-0548-4fcf-97d0-54e2d2dc6b12",
   "metadata": {},
   "source": [
    "## Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5756eca4-8936-4329-9ea8-8009e2071798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18f1c635-4438-4a38-977e-5d8da38183e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f00869e4c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting one of the datapoints, just to see\n",
    "all_values = training_data_list[76].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f67738-ac98-4a6f-96e1-8a98e6643723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transforming input to inspect how it looks\n",
    "\n",
    "# inputs_list = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "# inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "# print(len(inputs))\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa14120-f579-46aa-bd51-fff0b23df557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming output to inspect how it looks\n",
    "\n",
    "# # make array of right size (output_nodes) and fill with 0.1\n",
    "# targets = numpy.zeros(10) + 0.01\n",
    "# # first item in all_values is the target label for this record and should be 0.9\n",
    "# targets[int(all_values[0])] = 0.99\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e07b56ae-b597-41c5-a859-88a5c1769ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network (including rotated input)\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split each record on ','. all_values is list\n",
    "        all_values = record.split(',')\n",
    "        \n",
    "        #input\n",
    "        # scale and shift the inputs to be between 0.01 and 1 and is now an 1d array. leave out first item\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # output\n",
    "        # make array of right size (output_nodes) and fill with 0.01\n",
    "        targets = numpy.zeros(output_n) + 0.01\n",
    "        # first item in all_values is the target label for this record and should be 0.99\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        \n",
    "        #train the network\n",
    "        n.train(inputs, targets)\n",
    "        \n",
    "        \n",
    "#         ## create rotated inputs\n",
    "#         # rotated anticlockwise by x degrees\n",
    "#         #make input into 28x28, rotate it\n",
    "#         inputs_plusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), 10, cval=0.01, order=1, reshape=False)\n",
    "#         #train with rotated input, input transformed back into 784 array\n",
    "#         n.train(inputs_plusx_img.reshape(784), targets)\n",
    "#         # rotated clockwise by x degrees\n",
    "#         inputs_minusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -10, cval=0.01, order=1, reshape=False)\n",
    "#         #train with rotated input\n",
    "#         n.train(inputs_minusx_img.reshape(784), targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f374254-d170-4f29-a13f-47b56e0b36b8",
   "metadata": {},
   "source": [
    "## Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b404339-bd4c-49b9-b757-9a2fad0d5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e316faa8-4644-4dba-ba6e-99f8ff430e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# to be able to inspect later or save to computer i am collecting everything\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_predictions = []\n",
    "all_gold_labels = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split record on ',' \n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    all_gold_labels.append(correct_label)\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    all_inputs.append(inputs) \n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    all_outputs.append(outputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    all_predictions.append(label)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f795f80c-38be-420c-ac46-d600ff87e60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(scorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5b20492-f6b5-4897-9f3b-3c4ebf672718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9747\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5b23b7-f24c-4cc8-bf3a-3005461c7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting the incorrect predictions to see (this was from the mini sample data)\n",
    "\n",
    "# print('the network predicted this image to be ', all_predictions[7])\n",
    "# print('the correct answer is ', all_gold_labels[7])\n",
    "# all_values = test_data_list[7].split(',')\n",
    "# image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "# print(all_outputs[7]) #seeing which other numbers were also high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b940c1-0c81-491b-8a83-cb30cafa7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('the network predicted this image to be ', all_predictions[8])\n",
    "# print('the correct answer is ', all_gold_labels[8])\n",
    "# all_values = test_data_list[8].split(',')\n",
    "# image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "# print(all_outputs[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b98ab34-bce2-48f3-94b0-890bf5fa3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('the network predicted this image to be ', all_predictions[9])\n",
    "# print('the correct answer is ', all_gold_labels[9])\n",
    "# all_values = test_data_list[9].split(',')\n",
    "# image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "# print(all_outputs[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c091e-5236-4da0-9499-01d459a0664f",
   "metadata": {},
   "source": [
    "## Using my handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a276065-6085-4dbf-87ee-57d8bfbbfd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  my_own_images_thicker\\IMG_00.png\n",
      "0.36685812\n",
      "0.9931865\n",
      "loading ...  my_own_images_thicker\\IMG_01.png\n",
      "0.35814226\n",
      "1.0\n",
      "loading ...  my_own_images_thicker\\IMG_02.png\n",
      "0.35820824\n",
      "0.99955744\n",
      "loading ...  my_own_images_thicker\\IMG_03.png\n",
      "0.35820824\n",
      "1.0\n",
      "loading ...  my_own_images_thicker\\IMG_04.png\n",
      "0.3714587\n",
      "1.0\n",
      "loading ...  my_own_images_thicker\\IMG_05.png\n",
      "0.34744635\n",
      "1.0\n",
      "loading ...  my_own_images_thicker\\IMG_06.png\n",
      "0.35288942\n",
      "0.9979541\n",
      "loading ...  my_own_images_thicker\\IMG_07.png\n",
      "0.37074047\n",
      "0.9947899\n",
      "loading ...  my_own_images_thicker\\IMG_08.png\n",
      "0.3556536\n",
      "0.99611765\n",
      "loading ...  my_own_images_thicker\\IMG_09.png\n",
      "0.3579326\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# own image test data set\n",
    "my_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images_thicker/IMG_0?.png'):\n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "\n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "\n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    my_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd03d9aa-b14a-4339-8417-9b95098bb8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is  0.0\n",
      "network says  9\n",
      "no match!\n",
      "image is  1.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  2.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  3.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  4.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  5.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  6.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  7.0\n",
      "network says  8\n",
      "no match!\n",
      "image is  8.0\n",
      "network says  8\n",
      "match!\n",
      "image is  9.0\n",
      "network says  8\n",
      "no match!\n"
     ]
    }
   ],
   "source": [
    "# test the neural network with my own images\n",
    "\n",
    "# record to test\n",
    "for item in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    \n",
    "\n",
    "    # plot image\n",
    "    # matplotlib.pyplot.imshow(my_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = my_own_dataset[item][0]\n",
    "    # data is remaining values\n",
    "    inputs = my_own_dataset[item][1:]\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # print (outputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(\"image is \", correct_label)\n",
    "    print(\"network says \", label)\n",
    "    if (label == correct_label):\n",
    "        print (\"match!\")\n",
    "    else:\n",
    "        print (\"no match!\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f1d5d-513b-4f0d-9e67-9f8fa4cf8b9f",
   "metadata": {},
   "source": [
    "## Backwards query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1774abb8-8b51-49d4-b682-9384b3e38940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f008c94a60>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVaklEQVR4nO3dW2yd1ZUH8P8ikIsdJ7HjwdiJcxkngSQkkGAuUUbBVUVFiBDJQ0dFqMpIaNwHEK3Uh0HMQ3lEo2mrPgyIdIgaRh1QRYvIA8wUokqhIEJMEkhClAu52bHlXMiN3C9rHnyoTPC3/uZ8x+cczf7/pMj2Wd7nbH/2yrHP2mtvc3eIyP9/N1V6AiJSHkp2kUQo2UUSoWQXSYSSXSQRN5fzwerr672lpSUzftNN8f89165dK/qxzSyMX79+vejxrKLBvi42ns09T0WF3TeTd+4j+dh5xo4aNSrX+DxzYz8v0c9qb28vTp06NeRFz5XsZvYwgN8AGAXgP939hejzW1pa8Prrr2fGx44dGz7euXPnMmMsWW++Of5SL126FMZvueWWzNjFixfDsbW1tWH86tWrRT82G5/3vlmyXr58OYyPHj266PtmCXPlypUwHiUs+37X19eH8QsXLoTxPMk+ZsyYMB79vD3xxBOZsaJ/jTezUQD+A8ByAPMAPG5m84q9PxEZWXn+Zr8PwD533+/ulwG8DuCx0kxLREotT7JPAdA96OOewm3fYGadZtZlZl0nT57M8XAikkeeZB/qD65v/aHi7mvcvd3d29nfQSIycvIkew+A1kEfTwXQm286IjJS8iT7ZgCzzWymmY0G8CMA60szLREptaJLb+5+1cyeBvC/GCi9rXX3nWxcVCJjdfSo/sjGsnhUIgLiUgorrbEyD6vpshJTdE3zri8YN25cGGc14ahExcqhbO7sukTfM3bNz58/X/R9A/y6RCVLVs6MSnPRNctVZ3f3twG8nec+RKQ8tFxWJBFKdpFEKNlFEqFkF0mEkl0kEUp2kUSUtZ/d3cN6N6tHR7VNVrNl9WRWN41qm2zerF7MaroTJkwI49HXzr5uFj99+nQYZ/Xq6Gtn141hayOi71ne1l+G3X+e71nU4hqN1TO7SCKU7CKJULKLJELJLpIIJbtIIpTsIokoa+nNzMKSBitRRe2SrAzDsLbCqGUx77bCrP2Wlb+iHYDYzre9vfF+I6ykydp7J06cmBljX3dfX18Yb2hoCOPRdWOltcmTJ4fxmpqaMM52nz179mxmjJUzo+9JlEN6ZhdJhJJdJBFKdpFEKNlFEqFkF0mEkl0kEUp2kURUVYsrq5VHp7yymi2rF7Mtk8PWQbJtMKvZHjp0KIzv378/jEf16MbGxnBsdDIuAOzZsyeMszUAHR0dmTF2au/Ro0fDOGsFnT59emaMHUV27NixMM7Gs/jUqVMzY+zkpGKPwdYzu0gilOwiiVCyiyRCyS6SCCW7SCKU7CKJULKLJKLs/exRTZrVfIvt42Vjh6Ouri4zxraC3rx5cxjfu3dvGGc95wcOHMiMzZw5MxzLavhsjcDChQvD+HvvvZcZY2sj5s+fH8ZPnToVxtetW5cZW7ZsWTiWrR9gffxs++9oDQG7b7Y+IUuuDDCzgwDOArgG4Kq7t+e5PxEZOaV4Zv+eux8vwf2IyAjS3+wiicib7A7gz2b2iZl1DvUJZtZpZl1m1sXWC4vIyMmb7EvdfTGA5QCeMrNvverh7mvcvd3d29kCfxEZObmS3d17C2+PAngTwH2lmJSIlF7RyW5mtWZW9/X7AH4AYEepJiYipZXn1fgmAG8W6ts3A/hvd/+faIC7h/uzs/7kaCzrR2c1XVazjfqbjxw5Eo799NNPwzjbs56tP2hra8uMsfUHc+bMCeOs3szu/8EHH8yMsXoxW3/w4osvhvFobQXbk57N7auvvgrjhw8fDuP33HNPZuzMmTPh2OjrCo81D+814O77AdxV7HgRKS+V3kQSoWQXSYSSXSQRSnaRRCjZRRJR9q2ko/IaK+NEW03nPbKZlTui8tfWrVvDsVu2bAnj0ZbHALBjR7x8IToWuaWlJRybZwttANi1a1cY//jjjzNj7GhitsX2/fffH8ajdmq2dJv9LI4ZMyaMs5bqqPQ3bdq0cGyxx57rmV0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRJR9q2ko3o4O/o4qi9evXo1HMvi7Hjg7u7uzNjZs2fDsbfddlsYZ+23S5YsCeNvvPFGZoytAVi5cmUYj645wK/blClTMmNz584Nx7JtrlkbadQ6zGr80ZHKAF8DcOLEiTC+dOnSzBhbM3LlypXMWNTiqmd2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJRFnr7EBcB2RbKkf1RXZELutPbmpqCuNR/3Nzc3M4lm3HfOnSpTDOti1uaGjIjLH1Bey6sT7/BQsWhPGOjo7MGKvRs1762bNnh/Fbb701M8b6zdl1mTdvXhhfv359GL948WJm7MKFC+HY6Phw9bOLiJJdJBVKdpFEKNlFEqFkF0mEkl0kEUp2kUSUvc4e1QFra2vDsVE9mtWT2RG9bB/x3t7ezBirRbM6O1tfwI5VfuihhzJj/f394dienp4w3tnZGcZZrXz+/PmZsdtvvz0cG9WTAX6sctQXzursjY2NYZwd082+59ER4azOHvXi56qzm9laMztqZjsG3dZgZu+a2d7C23p2PyJSWcP5Nf53AB6+4bZnAWxw99kANhQ+FpEqRpPd3TcC+PKGmx8DsK7w/joAK0s7LREptWJfoGty9z4AKLzNXIRsZp1m1mVmXdHfKSIyskb81Xh3X+Pu7e7ePmnSpJF+OBHJUGyy95tZMwAU3sYvyYpIxRWb7OsBrC68vxrAW6WZjoiMFFpnN7PXAHQAaDSzHgC/APACgD+Y2ZMADgP44XAezN3DnnS2bzyLR9h52uxPjGjv98WLFxczpb9he7OzNQDRvvOtra3h2PHjx4dxVqdnawCiejRb+8Dq7LNmzQrjUT/7uXPnwrFsDwG2/8GyZcvCeLQnPls/wPa8z0KT3d0fzwh9v6hHFJGK0HJZkUQo2UUSoWQXSYSSXSQRSnaRRJT9yOaotTDaXheISw6sLMfaZydOnBjGjx8/nhljRzazdkfW6tnV1VX0ePZ1HThwIIw/+uijYZzdPzuuOsJKjgcPHgzj0feFlSTHjRsXxtnPW7S9NxD/LLMjvKOWaB3ZLCJKdpFUKNlFEqFkF0mEkl0kEUp2kUQo2UUSUfatpEcKq3vW1NSE8d27d4fxqAV206ZN4VhWR+/u7g7jbFvjjz76KDOWd/1B1IoJ8Fp4FP/iiy/CsWx78GnTphX92Gz7bnZcNLuurA01OuabbSUdzU1HNouIkl0kFUp2kUQo2UUSoWQXSYSSXSQRSnaRRJS1zu7uYX0zT+2SbRV94sSJMN7W1hbG33///czYnXfeGY5lxyKzI5/Z8cCLFi3KjLEtk1m9ed++fWGcHdk8d+7cou/7yy9vPGLwm1atWhXGozo7W/vArhv7WWXrDxYuXJgZi2rlQNzvrn52EVGyi6RCyS6SCCW7SCKU7CKJULKLJELJLpKIsu8bP3r06Mw4q11Ge86z/uOo/gjwvd+jvu9oXgDwwAMPhHF2PHC0Zz0QH328Z8+ecOyKFSvCOLsurB4dxdn6g71794bxGTNmhPHz589nxtg17ejoCOMbN24M4+wI8OiMBJYH0RHfufrZzWytmR01sx2DbnvezI6Y2bbCv0fY/YhIZQ3n1/jfAXh4iNt/7e53F/69XdppiUip0WR3940A4nWLIlL18rxA97SZfVb4Nb8+65PMrNPMusysi60XFpGRU2yyvwSgDcDdAPoA/DLrE919jbu3u3t7fX3m/wkiMsKKSnZ373f3a+5+HcBvAdxX2mmJSKkVlexmNngf3FUAdmR9rohUB1pnN7PXAHQAaDSzHgC/ANBhZncDcAAHAfxkOA9mZmENkfXxRrVy1pfNsFr3nDlzMmNNTU3hWHZGOavTs3PIo3ry2LFjw7EMO8ecne8exT/44INwbNSnD/Bz6yPsuhw+fLjo+wb4Xv9XrlzJjNXV1YVjo7UPUY7QZHf3x4e4+RU2TkSqi5bLiiRCyS6SCCW7SCKU7CKJULKLJKKqjmxm7ZLjx4/PjLG2wP7+/jDOjg+OWiLvvffecOylS5fCeEtLSxhnpbvoiN9nnnmm6LEAbzN9+eWXw3hUYurt7Q3HsiObp0yZEsajdmp2pDIr5TY0NIRx1nIdldfYY0dfl45sFhElu0gqlOwiiVCyiyRCyS6SCCW7SCKU7CKJKPuRzVHdlbUdRu177Ohg1rL44YcfhvHoyGd2XHRzc3MYZ6ZPnx7Go22L2XHQbA3A2rVrwzg7Cnvr1q2ZsXnz5oVj77jjjjCep5Yd1aoBvuaDXTc2t2h9A2v1jn7eVGcXESW7SCqU7CKJULKLJELJLpIIJbtIIpTsIomoqn52dqxyVJu8du1aODaq7wPxMbjs/llN9p133gnjCxYsCOOspzw6Tppt18z6+Hfu3BnG2XbO0R4ER44cCcey9QuLFy8O49H3jG3XzOrorNeebQ8ezY2NjbY9j+r7emYXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFElL3OHvXbsh7jqA7PavRsn29WK6+pqcmMsZ7unp6eMP7SSy+F8eXLl4fx6Jqy6/Lqq6+G8VWrVoVx1i8f1aNZ3zbbL//ixYthfP78+Zkxtu7i0KFDYby+vj6Ms1599viRqA6fq5/dzFrN7C9mtsvMdprZTwu3N5jZu2a2t/A2/upFpKKG82v8VQA/d/e5AB4A8JSZzQPwLIAN7j4bwIbCxyJSpWiyu3ufu28pvH8WwC4AUwA8BmBd4dPWAVg5QnMUkRL4Ti/QmdkMAIsAbALQ5O59wMB/CABuzRjTaWZdZtZ18uTJnNMVkWINO9nNbDyAPwL4mbvHr8oM4u5r3L3d3dvZixoiMnKGlexmdgsGEv337v6nws39ZtZciDcDiLd3FZGKoqU3G3gt/xUAu9z9V4NC6wGsBvBC4e1bw3nAqBTEjtGNSg4TJkwIx54+fTqMszbTqLzW3d0djt2zZ08YZ2UY1uIalfbYNWXlL9aeG5W3gLh8xr4n7EjmcePGhfEDBw5kxiZPnhyOZduaszg7djlqoWXHj7MSdZbh1NmXAvgxgO1mtq1w23MYSPI/mNmTAA4D+GFRMxCRsqDJ7u5/BZD13//3SzsdERkpWi4rkgglu0gilOwiiVCyiyRCyS6SiLK3uEY1RLZ9b1QzZu2OjY2NYXzFihVhPNrGmm3HPHv27DC+YcOGMM7ab48dO5YZYzXZu+66K4xHrb0AMGfOnDC+ffv2zBhbUTl37twwzrZcnjlzZmaMbR3Ojvhm6xeiLbSB+PvCvi62jXUWPbOLJELJLpIIJbtIIpTsIolQsoskQskukgglu0giylpnd/ewd5vVF1ktPRLVyYcj6l9mtWZW02XbPbOjjZcsWZIZa2trC8eyevHnn38expuamsJ4VEtnRy6zdRfR8cRA3O/Ovm62LoP1s+fZmyHP8eERPbOLJELJLpIIJbtIIpTsIolQsoskQskukgglu0giylpnN7Owj5fVVaOxefuLWc022l+d9Zu3traGcTa32traMB6tXdi3b184lu15z/ZmZ/XmRYsWZcZ6e3vDsWxP+2nTpoXxaG0F+56wn6cxY8aEcSbP3gyRaM2GntlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRwzmfvRXAqwBuA3AdwBp3/42ZPQ/gnwF8vWn5c+7+Nru/qBe3rq4uHBvVH1kPMIuz/dWjNQDNzc3h2IaGhjAenf0OAPv37w/jp06dCuORqVOnhnG25/3u3bvDeLQGYdasWeFYtq8826+ffV/yYHsQsL0ZovMT2L7wbA1A5pyG8TlXAfzc3beYWR2AT8zs3ULs1+7+70U9soiU1XDOZ+8D0Fd4/6yZ7QIwZaQnJiKl9Z3+ZjezGQAWAdhUuOlpM/vMzNaa2ZC/c5lZp5l1mVnXyZMn881WRIo27GQ3s/EA/gjgZ+5+BsBLANoA3I2BZ/5fDjXO3de4e7u7t7O/wURk5Awr2c3sFgwk+u/d/U8A4O797n7N3a8D+C2A+0ZumiKSF012G2g9egXALnf/1aDbB7/UuQrAjtJPT0RKZTivxi8F8GMA281sW+G25wA8bmZ3A3AABwH8hN2RmYUtkVGrJhCXz1g7JGufZW2q0bxZCyrb+pdtWzxhwoQwfvr06cwYK9OcP38+jE+aNCmMz5gxI4xHJSrWVpz3ukZYaYw9drHlr69F14W1zxZ7ZPNwXo3/K4ChMonW1EWkemgFnUgilOwiiVCyiyRCyS6SCCW7SCKU7CKJKPuRzZcvX86Ms9plnmOXWe2SxaM1AGx9wJkzZ8J4dE0AoKamJoxHWE2Wtf4yecazubHrkqcOz+rsbF0GW9fBvrbo542tP4jmHs1Lz+wiiVCyiyRCyS6SCCW7SCKU7CKJULKLJELJLpIIY1vilvTBzI4BODTopkYAx8s2ge+mWudWrfMCNLdilXJu093974YKlDXZv/XgZl3u3l6xCQSqdW7VOi9AcytWueamX+NFEqFkF0lEpZN9TYUfP1Ktc6vWeQGaW7HKMreK/s0uIuVT6Wd2ESkTJbtIIiqS7Gb2sJntNrN9ZvZsJeaQxcwOmtl2M9tmZl0VnstaMztqZjsG3dZgZu+a2d7C24qcqZUxt+fN7Ejh2m0zs0cqNLdWM/uLme0ys51m9tPC7RW9dsG8ynLdyv43u5mNArAHwEMAegBsBvC4u39e1olkMLODANrdveILMMxsGYCvALzq7ncWbvs3AF+6+wuF/yjr3f1fqmRuzwP4qtLHeBdOK2oefMw4gJUA/gkVvHbBvP4RZbhulXhmvw/APnff7+6XAbwO4LEKzKPquftGAF/ecPNjANYV3l+HgR+WssuYW1Vw9z5331J4/yyAr48Zr+i1C+ZVFpVI9ikAugd93IPqOu/dAfzZzD4xs85KT2YITe7eBwz88AC4tcLzuRE9xrucbjhmvGquXTHHn+dViWQfapOsaqr/LXX3xQCWA3iq8OuqDM+wjvEulyGOGa8KxR5/nlclkr0HQOugj6cC6K3APIbk7r2Ft0cBvInqO4q6/+sTdAtvj1Z4Pn9TTcd4D3XMOKrg2lXy+PNKJPtmALPNbKaZjQbwIwDrKzCPbzGz2sILJzCzWgA/QPUdRb0ewOrC+6sBvFXBuXxDtRzjnXXMOCp87Sp+/Lm7l/0fgEcw8Ir8FwD+tRJzyJjX3wP4tPBvZ6XnBuA1DPxadwUDvxE9CWAygA0A9hbeNlTR3P4LwHYAn2EgsZorNLd/wMCfhp8B2Fb490ilr10wr7JcNy2XFUmEVtCJJELJLpIIJbtIIpTsIolQsoskQskukgglu0gi/g8yeQLQKSklPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 5\n",
    "\n",
    "# create array with length 10 and fill with 0.01\n",
    "targets = numpy.zeros(output_n) + 0.01\n",
    "# label we defined is index for target to make 0.99\n",
    "targets[label] = 0.99\n",
    "\n",
    "print(targets)\n",
    "\n",
    "# query nn backwards\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbd3bf-03c1-467c-b3bc-67e0c19646a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
